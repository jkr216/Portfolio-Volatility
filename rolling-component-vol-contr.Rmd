---
title: "Rolling Component Volatility Contribution"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

```{r setup, message = FALSE}
library(tidyverse)
library(tidyquant)
library(highcharter)
```

```{r, message=FALSE, warning=FALSE}

symbols <- c("SPY","IJS","EFA","EEM","AGG")

prices <- 
  getSymbols(symbols, src = 'google', from = "2005-01-01", 
             auto.assign = TRUE, warnings = FALSE) %>% 
  map(~Cl(get(.))) %>% 
  reduce(merge) %>%
  `colnames<-`(symbols)

prices_monthly <- to.monthly(prices, indexAt = "first", OHLC = FALSE)

portfolioComponentReturns <- na.omit(Return.calculate(prices_monthly, method = "log"))

w = c(0.25, 0.20, 0.20, 0.25, 0.10)
```


```{r}
# Before we get to substance, let's practice toggling between a tibble and an xts. 
# Why? Our financial data will frequently be imported as an xts object, 
# but we'll want to wrangle, tidy and map functions to tibbles, before visualzing
# with dygraphs or highcharter, which take an xts object. 

returns_df <- 
  portfolioComponentReturns %>% 
  as_tibble(preserve_row_names = TRUE) %>% 
  mutate(date = ymd(row.names)) %>% 
  select(-row.names) %>% 
  select(date, everything())

returns_xts <- returns_df %>% 
  as_xts(date_col = date)
```

First, we need to build a function to calculate the rolling contribution of each asset.  The previous sectio told us the total contribution of each asset over the life of the portfolio, but it did not help us understand risk components over time. As we discussed in our section on rolling portfolio volatility, there's reasons to care about rolling. 

Some reasons for brief review:

Our goal is to create a function that takes (1) a `data.frame` of asset returns and calculates the rolling contributions of each asset to volatility, based on a (2) starting date index and a (3) window, for a portfolio (4) with specified weights of each asset.  We will need to supply four arguments to the function, accordingly.

Here's the logic I used to construct that function (feel free to eviscerate this logic and replace it with something better).  

1. Assign a start date and end date based on the window argument. If we set window = 6, we'll be calculating 6-month rolling contributions. 
2. Use `filter()` to subset the original `data.frame` down to one window. I label the subsetted data frame as `interval_to_use`. In our example, that interval is a 6-month window of our original data frame. 
3. Now we want to pass that `interval_to_use` object to `StdDev()` but it's not an `xts` object. We need to convert it and label it `returns_xts`. 
4. Before we call `StdDev()`, we need weights. Create a weights object called `w` and give the value from the argument we supplied to the function.
5. Pass the `returns_xts` and `w` to `StdDev()`, and set `portfolio_method = "component"`.
6. We now have an object called `results_as_xts`. What is this? It's the risk contributions for each asset during the first 6-month window of our weighted portfolio. 
7. Convert it back to a `tibble` and return.
8. We now have the risk contributions for the 6-month period that started on the first date, because we default to `start = 1`. If we wanted to get the standard deviation for a 6-month period that started on the second date, we could set `start = 2`, etc.

```{r SD Interval Function, message = FALSE}

my_interval_sd <- function(returns_df, start = 1, window = 6, weights){
  
  # First create start date. 
  # For now let's always start at the first date for which we have data. 
  start_date <- returns_df$date[start]
  
  # Next an end date.
  end_date <-  returns_df$date[c(start + window)]
  
  # Filter on start and end date.
  interval_to_use <- returns_df %>% filter(date >= start_date & date < end_date)
  
  # Convert to xts so can use built in Performance Analytics function.
  returns_xts <- interval_to_use %>% as_xts(date_col = date) 
  
  # Portfolio weights.
  w <- weights
  
  # Pass xts object to function.
  results_as_xts <- StdDev(returns_xts, weights = w, portfolio_method = "component")
  
  # Convert results to tibble.
  results_to_tibble <- as_tibble(t(results_as_xts$pct_contrib_StdDev)) %>% 
    mutate(date = ymd(end_date)) %>% 
    select(date, everything()) 
}
```

We're halfway there, though, because we need to apply that function starting at the first date in our `returns_df` object, and keep applying it to successive date indexes until the date that is 6-months before the final date. Why end there? Because there is no rolling 6-month contribution that starts only 1, 2, 3, months ago! 

We will invoke `map_df()` to apply our function to date 1, then save the result to a `data.frame`, then apply our function to date 2, and save to that same `data.frame`, and so on until we tell it stop at the at index that is 6 months before the last date index.

```{r, message=FALSE, warning=FALSE}
window <- 6

rolling_vol_contributions <- 
  map_df(1:(nrow(returns_df) - window), my_interval_sd, returns_df = returns_df, 
         window = window, weights = w) %>%
  mutate(date = ymd(date)) %>% 
  select(date, everything()) %>%
  # Convert back to xts so we can use highcharter for visualizations.
  as_xts(date_col = date) %>% 
  round(., 4) *100

test <- rolling_vol_contributions %>% round(., 4) *100

```

Now we can visualize with `highcharter` by adding the rolling conbtribution of each asset to a chart. 

```{r, message = FALSE}

  highchart(type = "stock") %>% 
  hc_title(text = "Volatility Contribution") %>%
  hc_add_series(rolling_vol_contributions$SPY, name = "SPY", id = "SPY") %>%
  hc_add_series(rolling_vol_contributions$IJS, name = "IJS") %>%
  hc_add_series(rolling_vol_contributions$EFA, name = "EFA" )%>%
  hc_add_series(rolling_vol_contributions$AGG, name = "AGG") %>%
  hc_add_series(rolling_vol_contributions$EEM, name = "EEM") %>%
  hc_yAxis(labels = list(format = "{value}%"), max = 100, opposite = FALSE) %>%
  hc_navigator(enabled = FALSE) %>% 
  hc_scrollbar(enabled = FALSE)
```

For some reason, EEM rolling volatility spiked in June. Did something roil emerging markets in the preceding months? And IJS vol plunged, which seems unusual for a small-cap fund. AGG and EFA have had stable volatilities. 

There are plenty of future applications if we ever get bored over a weekend: 
-subset by spikes, perhaps whenever x asset went above this threshold for risk contribution.
-label any cross overs
-try to explain when a certain goes above the thresh
-calculate portfolio that puts to parity at time x
-compare to the Vix
- compare to oil prices
- compare to a random portfolio
- compare to SP500 or a sector